{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9QNx_viE0rW"
      },
      "source": [
        "## 1. LSTM 모델을 이용한 NLP Classification (스팸 메일 분류기)\n",
        "\n",
        "### 이번 실습에서는 LSTM 모델을 사용하여 스팸 메일을 분류하는 과정을 LSTM 설계, 데이터 전처리 과정을 통해 알아봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsUtIyhNE0rY"
      },
      "source": [
        "**1.1 Fully Connected Layer 복습**\n",
        "\n",
        "RNN과 LSTM 모델을 학습하기에 앞서 기본적인 ANN (Fully Connected Layer)를 Pytorch로 구성하는 것을 복습합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtC9ZYyLE0rZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class ANN(nn.Module):\n",
        "    def __init__(self, num_output, input_size, hidden_size, device):\n",
        "        super(ANN, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.outlayer = nn.Linear(hidden_size, num_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.fc1(x).relu()\n",
        "        h = self.fc2(h).relu()\n",
        "        predict = self.outlayer(h)\n",
        "        return predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAjRkpHZE0ra"
      },
      "source": [
        "**1.2 LSTM for NLP**\n",
        "\n",
        "가장 보편적으로 쓰이는 recurrent neural network 구조인 LSTM을 PyTorch로 꾸미는 과정입니다. 기본적으로 텍스트를 다룰 때에는 word2vec을 사용해도 되지만, nn.Embedding 레이어를 사용해서 정수 인코딩 결과를 word2vec으로 만들어주는 레이어를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K30Rw8VE0rb"
      },
      "outputs": [],
      "source": [
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, num_output, size_vocab, dim_embed, hidden_size, linear_size, num_layers, device):\n",
        "        super(LSTM_net, self).__init__()\n",
        "        self.device = device # GPU\n",
        "        self.num_output = num_output # 1\n",
        "        self.hidden_size = hidden_size # 128\n",
        "        self.num_layers = num_layers # 2\n",
        "\n",
        "        self.embed = nn.Embedding(size_vocab, dim_embed)\n",
        "\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = dim_embed, hidden_size = hidden_size,\n",
        "                            num_layers = num_layers, dropout = 0.3, bidirectional = True)\n",
        "        self.fclayer = nn.Linear(hidden_size, linear_size)\n",
        "        self.outlayer = nn.Linear(linear_size, num_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        scaler = 2 if self.lstm.bidirectional == True else 1\n",
        "\n",
        "        emb = self.embed(x)\n",
        "\n",
        "        h_state = Variable(torch.zeros(self.num_layers*scaler, emb.size(0),\n",
        "                                       self.hidden_size, requires_grad = True)).to(self.device)\n",
        "        c_state = Variable(torch.zeros(self.num_layers*scaler, emb.size(0),\n",
        "                                       self.hidden_size, requires_grad = True)).to(self.device)\n",
        "\n",
        "        lstm_out, (h, c) = self.lstm(emb.transpose(1,0), (h_state, c_state))\n",
        "        h = h[-1]  # important\n",
        "        h = self.fclayer(h).relu()\n",
        "        predict = self.outlayer(h)\n",
        "        return predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLz8XN54E0rc"
      },
      "source": [
        "**1.3 Spam Mail Classification: 데이터 전처리**\n",
        "\n",
        "스팸 메일을 분류할 수 있는 이진 분류기를 LSTM을 이용하여 꾸며보는 예시입니다. 우선 csv 파일을 받아 토큰화, 정제 및 추출, 정수 인코딩 과정을 거칩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_aVCyZJE0rc",
        "outputId": "26b88666-9346-4cb6-cac1-87dd4cfa801f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5728 entries, 0 to 5727\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    5728 non-null   object\n",
            " 1   spam    5728 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 89.6+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Subject: naturally irresistible your corporate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Subject: 4 color printing special  request add...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: do not have money , get software cds ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Subject: naturally irresistible your corporate...     1\n",
              "1  Subject: the stock trading gunslinger  fanny i...     1\n",
              "2  Subject: unbelievable new homes made easy  im ...     1\n",
              "3  Subject: 4 color printing special  request add...     1\n",
              "4  Subject: do not have money , get software cds ...     1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "data = pd.read_csv(\"emails.csv\")\n",
        "display(data.info(),data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX0b-DDeE0re"
      },
      "source": [
        "**토큰화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGOPTzhOE0re",
        "outputId": "2888c8e4-5619-4cb3-feb6-fdb61291d263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After cleaning : 5728\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "stop_words = set(stopwords.words('english'))\n",
        "data = data.dropna().reset_index(drop=True)\n",
        "token_text = []\n",
        "for i in range(5728):\n",
        "    token = word_tokenize(data.iloc[i,0])\n",
        "    token_stop_text = []\n",
        "    for w in token:\n",
        "        if w not in stop_words:\n",
        "            token_stop_text.append(w)\n",
        "    token_text.append(token_stop_text)\n",
        "print('After cleaning :', len(token_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82PgIc8VE0rf"
      },
      "source": [
        "**정수 인코딩**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb9e7CZWE0rf",
        "outputId": "4b20e6f9-a574-4f7e-c4a0-375d4609a635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37231\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(token_text)\n",
        "print(len(tokenizer.word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-S0EdmYE0rg",
        "outputId": "359d4b6d-205a-44dc-f63d-ec75142c842f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13, 4, 5717, 12190, 440, 1686, 3812, 377, 820, 4317, 68, 4, 78, 325, 6211, 43, 9097, 39, 120, 4428, 752, 3, 5963, 5964, 1585, 223, 82, 2067, 169, 1756, 2, 1899, 7930, 1613, 4211, 68, 10916, 597, 332, 5718, 4, 6476, 7931, 407, 120, 280, 3, 787, 50, 768, 4429, 2958, 4556, 4318, 78, 39, 1899, 374, 693, 597, 169, 787, 2, 123, 930, 1194, 4, 4430, 4, 1013, 1, 241, 3, 211, 2413, 3, 3448, 477, 1937, 4212, 68, 1166, 2, 1045, 4, 752, 1348, 617, 2475, 39, 749, 1, 1, 115, 603, 77, 188, 4557, 370, 223, 603, 365, 874, 2, 4431, 4, 83, 752, 4098, 197, 424, 50, 217, 2, 4432, 4, 374, 1292, 1, 11, 82, 3652, 1262, 2, 406, 107, 2026, 1195, 4, 190, 1880, 647, 356, 1391, 1957, 4558, 1211, 831, 2304, 2, 105, 608, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 159, 2, 2, 2, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7]\n"
          ]
        }
      ],
      "source": [
        "text_encoded = tokenizer.texts_to_sequences(token_text)\n",
        "print(text_encoded[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsxl0QPcE0rg"
      },
      "source": [
        "**학습을 위한 Label: Spam인 경우 1, Normal Text인 경우 0**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJ8FVkR6E0rg"
      },
      "outputs": [],
      "source": [
        "text_label = np.array(data.iloc[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_bBZqavE0rg"
      },
      "source": [
        "**Padding 및 데이터 자르기**\n",
        "\n",
        "이메일은 보통 다수의 문장으로 이루어져 있기 때문에, 정제 및 추출을 거치더라도 1개 샘플의 길이가 길 수 있습니다. 따라서 maxlen을 설정하여, maxlen 이하의 토큰을 가진 이메일은 padding을, maxlen 이상의 토큰을 가진 이메일은 첫 100개만 사용하고 나머지는 버립니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQQtIxQXE0rg",
        "outputId": "cc17d301-dabe-4513-e351-d815e42bda8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5728,)\n",
            "(5728,)\n",
            "5599\n",
            "(5728, 100)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(text_encoded))\n",
        "print(np.shape(text_label))\n",
        "maxlen = 0\n",
        "for w in text_encoded:\n",
        "    if len(w) >= maxlen:\n",
        "        maxlen = len(w)\n",
        "print(maxlen)\n",
        "\n",
        "maxlen = 100\n",
        "rowdata = []\n",
        "for w in text_encoded:\n",
        "    if len(w) >= maxlen:\n",
        "        rowdata.append(w[:maxlen])\n",
        "    else:\n",
        "        rowdata.append(np.pad(w, (0, maxlen), 'constant', constant_values=0)[:maxlen])\n",
        "text_padded = np.concatenate(rowdata, axis=0).reshape(-1, maxlen)\n",
        "print(np.shape(text_padded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qEajXJVE0rh"
      },
      "source": [
        "**1.4 학습을 위한 Dataset 만들기 및 학습 과정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKOWEPCSE0rh"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from torch import LongTensor as LT\n",
        "from torch import FloatTensor as FT\n",
        "\n",
        "class Generate_Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,xdata, ydata,device):\n",
        "        self.x_data = xdata\n",
        "        self.y_data = ydata\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "    def __getitem__(self, idx):\n",
        "        x = LT(self.x_data[idx]).to(self.device)\n",
        "        y = LT(self.y_data[idx]).to(self.device)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv9xzdtpE0rh"
      },
      "source": [
        "**Generate Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJoEF3mwE0rh"
      },
      "outputs": [],
      "source": [
        "dataset = Generate_Dataset(text_padded[:5000,:], text_label[:5000].reshape([-1,1]), device)\n",
        "trainset, testset = random_split(dataset, [4500,500])\n",
        "train_loader = DataLoader(trainset, batch_size=256, shuffle = True)\n",
        "test_loader = DataLoader(testset, batch_size = 500, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6WULIZME0rh"
      },
      "source": [
        "**Define Network and Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTw_0Qg5E0rh"
      },
      "outputs": [],
      "source": [
        "lstm_net = LSTM_net(num_output = 2, size_vocab = len(tokenizer.word_index), dim_embed = 64,\n",
        "                    hidden_size = 64, linear_size = 64, num_layers = 1, device = device)\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm_net.parameters(), lr = 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVup53wuE0rh"
      },
      "source": [
        "**Training Session**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRqnlMkdE0rh",
        "outputId": "c3ffa4cf-df36-4f43-efe8-0fd6ad6b846e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.3029, grad_fn=<NllLossBackward>)\n",
            "Epoch 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0551, grad_fn=<NllLossBackward>)\n",
            "Epoch 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0084, grad_fn=<NllLossBackward>)\n",
            "Epoch 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0022, grad_fn=<NllLossBackward>)\n",
            "Epoch 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0595, grad_fn=<NllLossBackward>)\n",
            "Epoch 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0032, grad_fn=<NllLossBackward>)\n",
            "Epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0107, grad_fn=<NllLossBackward>)\n",
            "Epoch 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0001, grad_fn=<NllLossBackward>)\n",
            "Epoch 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ...\n",
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.9004e-05, grad_fn=<NllLossBackward>)\n",
            "Epoch 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2.1635e-05, grad_fn=<NllLossBackward>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "for epoch in range(10):\n",
        "    print('Epoch',epoch)\n",
        "    with tqdm(train_loader, unit = 'batch') as tepoch:\n",
        "        for x, y in tepoch:\n",
        "            predict = lstm_net(x)\n",
        "            loss = torch.nn.functional.cross_entropy(predict, y.ravel())\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(loss)\n",
        "            #print(loss)\n",
        "            #tepoch.set_description(f\"Epoch {epoch}\")\n",
        "            #tepoch.set_postfix(loss = loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri4ZX8-hE0ri"
      },
      "source": [
        "**Test the Performance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Kz2eNXyE0ri",
        "outputId": "fbb96a04-3928-4112-d027-315e5d021299"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " ... (more hidden) ..."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "486 out of 500, accuracy is 97.2 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "with tqdm(test_loader, unit='batch') as tepoch:\n",
        "    for x, y in tepoch:\n",
        "        predict = lstm_net(x).argmax(1).detach().numpy()\n",
        "        answer = y.ravel().detach().numpy()\n",
        "score = 0\n",
        "for i in range(len(predict)):\n",
        "    if predict[i] == answer[i]:\n",
        "        score += 1\n",
        "print(score,'out of 500, accuracy is',score/500*100,'%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CE27GemE0ri"
      },
      "source": [
        "## 2. seq2seq 모델을 이용한 NLP machine translation\n",
        "\n",
        "### 이번 실습에서는 LSTM 모델을 이용한 seq2seq 모델에서 기계 번역을 구현합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5NNNhtQE0ri"
      },
      "source": [
        "**2.1 Download Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqh4b9AIE0rj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import spacy\n",
        "os.system(\"python -m spacy download en_core_web_sm\")\n",
        "os.system(\"python -m spacy download de_core_news_sm\")\n",
        "\n",
        "# Source from [1]\n",
        "spacy_german = spacy.load('de_core_news_sm')\n",
        "spacy_english = spacy.load('en_core_web_sm')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSifgvY8E0rj"
      },
      "outputs": [],
      "source": [
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_german.tokenizer(text)][::-1]\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_english.tokenizer(text)]\n",
        "SRC = Field(tokenize = tokenize_de, init_token = '<sos>', eos_token = '<eos>', lower = True)\n",
        "TRG = Field(tokenize = tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbJvdl8_E0rj"
      },
      "outputs": [],
      "source": [
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJbfR0IwE0rj"
      },
      "outputs": [],
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24i0EDQGE0rj"
      },
      "source": [
        "**2.2 Network Structures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTmCguN0E0rj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class seq_Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, dim_embed, hidden_size, num_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, dim_embed)\n",
        "        self.lstm = nn.LSTM(dim_embed, hidden_size, num_layers, dropout = dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        outputs, (hidden, cell) = self.lstm(self.dropout(self.embed(src)))\n",
        "        return hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7DJRjJRE0rk"
      },
      "outputs": [],
      "source": [
        "class seq_Decoder(nn.Module):\n",
        "    def __init__(self, output_size, dim_embed, hidden_size, num_layers, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embed = nn.Embedding(output_size, dim_embed)\n",
        "        self.lstm = nn.LSTM(dim_embed, hidden_size, num_layers, dropout = dropout)\n",
        "        self.fclayer = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_data, hidden, cell):\n",
        "\n",
        "        input_data = input_data.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embed(input_data))\n",
        "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
        "        prediction = self.fclayer(output.squeeze(0))\n",
        "\n",
        "        return prediction, hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2RJdyG0E0rk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "class seq2seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, source, target, tf_ratio = 0.5):\n",
        "        batch_size = target.shape[1]\n",
        "        translation_length = target.shape[0]\n",
        "        target_vocab_size = self.decoder.output_size\n",
        "\n",
        "        outputs = torch.zeros(translation_length, batch_size, target_vocab_size).to(self.device)\n",
        "        hidden, cell = self.encoder(source)\n",
        "        input_trans = target[0,:]\n",
        "\n",
        "        for t in range(1, translation_length):\n",
        "            output, hidden, cell = self.decoder(input_trans, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < tf_ratio\n",
        "            input_trans = target[t] if teacher_force else output.argmax(1)\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do9HAI5HE0rk",
        "outputId": "2184c365-05a3-4923-9638-247e436bcabd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Owner\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "enc = seq_Encoder(len(SRC.vocab), 64, 64, 1, 0.3)\n",
        "dec = seq_Decoder(len(TRG.vocab), 64, 64, 1, 0.3)\n",
        "seq_net = seq2seq(enc, dec, device).to(device)\n",
        "optimizer = torch.optim.Adam(seq_net.parameters(), lr = 0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6xPMsBdE0rk"
      },
      "outputs": [],
      "source": [
        "from torchtext.legacy.data import BucketIterator\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data),\n",
        "                                                                      batch_size = 256, device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnydXZ7cE0rk"
      },
      "source": [
        "**2.3 Train the Translator Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTH9ta5lE0rx",
        "outputId": "e968b0cc-0b4c-4788-8e22-5102e0a24f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Loss 5.136473542765567\n",
            "Epoch 1 Loss 4.546293902815434\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-48-421b60ee663f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfcn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss_epoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "pad_index = TRG.vocab.stoi[TRG.pad_token]\n",
        "lossfcn = nn.CrossEntropyLoss(ignore_index = pad_index)\n",
        "\n",
        "for epoch in range(10):\n",
        "    loss_epoch = 0\n",
        "    for batch in train_iterator:\n",
        "        source_data = batch.src\n",
        "        target_data = batch.trg\n",
        "        target_pred = seq_net(source_data, target_data)\n",
        "        target_pred = target_pred[1:].view(-1, target_pred.shape[-1])\n",
        "        target_data = target_data[1:].view(-1)\n",
        "        optimizer.zero_grad()\n",
        "        loss = lossfcn(target_pred, target_data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_epoch += loss.item()\n",
        "    print('Epoch',epoch,'Loss',loss_epoch/len(train_iterator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUst0nnSE0ry"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZL-5xnoaE0ry"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jswAzZfBE0ry"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}